{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf9c335-bd1c-4d54-9b8d-9dc0049b7418",
   "metadata": {},
   "source": [
    "# CS405 Machine Learning Lab \n",
    "### #4 Linear Regression\n",
    "\n",
    "### 1. Introduction\n",
    "As you have learnt linear regression in the lecture, now it is time to implement the machine learning techniques in practice. In this lab, you will use linear regression to fit a house price model. You will use some real-world data as the test set to evaluate your model. The scikit-learn package for Python provides many modules for easily developing machine learning algorithms.\n",
    "\n",
    "### 2. Scikit learn package\n",
    "Implementation of a linear regression by scratch is not difficult, but here we use the scikit-learn package for Python directly. This package contains many classical machine learning algorithms and is easy to use.\n",
    "\n",
    "**Datasets: ** scikit-learn provides a number of datasets which can be directly loaded by using a function. There are some small datasets called *toy datasets* and some large ones with thousands of samples called real world datasets. First we load a toy dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168de7e-9006-442e-811f-2a3887ff72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a0ead-6b03-4330-a2cb-59e478ee777d",
   "metadata": {},
   "source": [
    "See [sklearn website](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) for details. To do this you have to import right packages and modules. This is a small dataset containing 506 samples and 13 attributes. We need to use proper visualization methods to have an intuitive understanding. We choose the sixth attribute and draw a scattering plot to see the distribution of samples. We use *matplotlib* for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27e0ea-3329-4cb1-94fd-0df50318a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one feature for visualization\n",
    "x = boston.data[:,5]\n",
    "\n",
    "# Get the target vector\n",
    "y = boston.target\n",
    "\n",
    "# Scattering plot of prive vs. room number\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a5c9c-7c6a-4140-a988-f717a9378057",
   "metadata": {},
   "source": [
    "It can be seen that the samples have some exceptional distributions at the top of the plot. They may be outliers owing to some practical operation during the data input (e.g., convert any price larger than 50 into 50). However, these data are harmful to the model training, and should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21be2e-7c94-4b2e-85ca-43a6d1be47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[y<50.0]\n",
    "y = y[y<50.0]\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230542c-3e58-4c00-99a8-91b338a6de24",
   "metadata": {},
   "source": [
    "Now it can be seen that the data is nearly linear, although just in one dimension. Now we use X to denote all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e3ca3-e1fa-4cc2-937b-d5484fe81824",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y<50.0]\n",
    "y = y[y<50.0]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd39f2-1fc9-4431-ab1c-03464348f53d",
   "metadata": {},
   "source": [
    "#### Split data\n",
    "Now we divide the whole dataset into a training set and a test set using the the scikit-learn model_selection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27b91d-7304-47de-aad2-7046ba8be2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad7e0a-f00d-47bb-8666-687ca24e50d8",
   "metadata": {},
   "source": [
    "Usually we also use a validation set. When we use the test set for evaluation, the model will not be changed after the evaluation. However, sometime we want to optimize our model by changing its parameters according to prediction results. The solution is to split a validation set from the training set for adjusting our model. When we believe that the model is good enough, then we evaluate our model on the test set. A more rigorous and costly way is cross validation. With that method, the training set is divided into several pieces in the same size and take every piece as a validation set in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379001a-8a61-44f3-a4c6-0466a010d54e",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "Now we try to implement a simple linear regression model because the dataset seems linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01200cd-e57e-4262-b863-87524e8612c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6873d-c8e3-42f5-9f92-7918c20e5522",
   "metadata": {},
   "source": [
    "The model has been trained just by using a few lines of codes. Now let’s make a prediction for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e4549-50de-4ff4-9fb2-149fff246b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "y_0_hat = lin_reg.predict(X_test[0].reshape(1,-1))\n",
    "y_0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca02f7d-80cd-40c4-aa80-00b7110b8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d8d8d-5da1-4158-906a-4ec11f6a16d5",
   "metadata": {},
   "source": [
    "Notice that in scikit-learn, the standard interface for machine learning is\n",
    "1) instantiate a learner with super parameters or none; \n",
    "2) use `fit()` method and feed the learner with training data; \n",
    "3) use `predict()` for prediction. \n",
    "\n",
    "Moreover, the data preprocessing algorithms also have the same interface, they just use `transform()` instead of `predict()`.\n",
    "\n",
    "Below are the trained parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8204c34-0235-4610-9429-a5d8443beec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd5540-43c4-4c12-97a5-dce6cc1a197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90131c-e5d9-495f-b282-9d91ab231141",
   "metadata": {},
   "source": [
    "Use the evaluation method to see if it is a good model. The `score()` method uses R-square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c32e70-0bb7-4044-be7b-b43360e9a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f03edb-37ef-4fca-980b-7b755da5f1d5",
   "metadata": {},
   "source": [
    "### 3.Polynomial Regression\n",
    "If you have understood the concept of linear regression, you can easily implement polynomial regression. Just a little bit more you should know:\n",
    "\n",
    "1) Extend the attributes to polynomial attributes. we can achieve that easily by using scikit-learn. See PolynomialFeatures in module preprocessing.\n",
    "2) When using polynomial features upon data, the values would be extremely large or small because of the power operation. That will influence the use of gradient descent which runs in background when we call `fit()`. So a normalization or standardization is necessary. See StandardScaler in preprocessing.\n",
    "3) Pipeline can help us assemble several preprocessing functions and the learning process together. The `poly_reg` learner has the same interface as other learners.\n",
    "\n",
    "```Python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_reg = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "``` \n",
    "\n",
    "\n",
    "4) Regularization in scikit learn is `RidgeRegression`, which is in `linear_model`. Use it if you need regularization in your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8985e-053c-42b0-9d94-e458c21d6491",
   "metadata": {},
   "source": [
    "### 4. Lab Excercises\n",
    "Please use the real world dataset, **California housing price**, for model training and evaluate the model’s prediction performance. You can use simple linear regression, polynomial regression or more complicated base functions such as Gaussian function or use regularization methods. Make sure at least **20% data for testing** and choose one evaluation method you think good. **Please do not just train your model and say that is good enough, you need to analyze the bias and variance**. For that end, validation or cross validation is needed. Compare the score in the training set and the validation set. If they are both good enough, then use the model on the test set.\n",
    "\n",
    "**Your test set can only be used for final evaluation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04fd22-a7b9-4eb4-a4f0-45a60f2b2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2441ed-28fe-48ca-a2cd-52834adc0db4",
   "metadata": {},
   "source": [
    "### 5. Questions\n",
    "1) Describe another real-world application where the regression method can be applied\n",
    "2) What are the strengths of the linear/polynomial regression methods; when do they perform well?\n",
    "3) What are the weaknesses of the linear/polynomial regression methods; when do they perform poorly?\n",
    "4) What makes the linear regression method a good candidate for the regression problem, if you have enough knowledge about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a964f3-337e-4b48-8973-3e411af73f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
