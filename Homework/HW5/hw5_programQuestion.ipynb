{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAqXcDzKwj4D"
   },
   "source": [
    "# HW5_programQuestion\n",
    "\n",
    "**Due to 11:55 am, 20th, November 2019**\n",
    "\n",
    "**This is an individual assignment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqy1LtZCIQuG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n",
    "import tensorflow as tf\n",
    "# if any exception related to tensorflow happens: \n",
    "# try to use 'import tensorflow.compat.v1 as tf' and add 'tf.disable_v2_behavior()'\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "try:\n",
    "    from StringIO import StringIO  # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO         # Python 3.x\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=img.shape[0],\n",
    "                                       width=img.shape[1])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        \n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values**2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()\n",
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9fIU8eP_X1u"
   },
   "source": [
    "# Convolutional Neural Networks  \n",
    "In this assignment you will be training a Convolutional Neural Network on  \n",
    "the Fashion MNIST dataset.  \n",
    "\n",
    "You may find more information about the dataset [here](https://github.com/zalandoresearch/fashion-mnist).  \n",
    "For this assignment we have already loaded the dataset for you.  \n",
    "  \n",
    "You will be using PyTorch for implementing your CNN. \n",
    "\n",
    "**We highly recommend following [this tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) for this question** as well as referring to the [official documentation](https://pytorch.org/docs/stable/nn.html) if you are unfamiliar with Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvDAZByo_X1w"
   },
   "source": [
    "## 1. Loading the Dataset\n",
    "The output of torchvision datasets are PILImage images of range [0, 1].  \n",
    "We transform them to Tensors of normalized range [-1, 1].  \n",
    "```Transforms.Normalize((mean,),(std,))``` basically manipulates the values of a pixel such that  \n",
    "$$New\\_Value = \\frac{Old\\_Value - Mean}{Std}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lK7aviwP_X1x"
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "\n",
    "#TODO : Set the value of mean and the standard deviation to \n",
    "#       normalize the image from range [0,1] to the range [-1, 1]\n",
    "\n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "mean = \n",
    "std = \n",
    "\n",
    "#End Your Code\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((mean,), (std,))\n",
    "                                ])\n",
    "\n",
    "\n",
    "#TODO : Select suitable value of batch_sizes.\n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "train_batch_size = \n",
    "test_batch_size = \n",
    "\n",
    "#End Your Code\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Classes\n",
    "classes = {       0 :'T-shirt/top',\n",
    "                  1 :'Trouser',\n",
    "                  2 :'Pullover',\n",
    "                  3 :'Dress',\n",
    "                  4 :'Coat',\n",
    "                  5 :'Sandal',\n",
    "                  6 :'Shirt',\n",
    "                  7 :'Sneaker',\n",
    "                  8 :'Bag',\n",
    "                  9 :'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFBh6ZhO_X1y"
   },
   "source": [
    "## 2. The Dataset\n",
    "Here we show some images of the dataset.  \n",
    "See how many of the categories can you recognise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hX5Irrw-_X1z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "\n",
    "# Functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    figure(num=None, figsize=(8, 6), dpi=150, edgecolor='k')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le9N91sO_X11"
   },
   "source": [
    "## 3. Create your Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWmqB-1b_X11"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        #TODO : Design your network, you are allowed to explore your own architecture\n",
    "        #       But you should achieve a better overall accuracy than the baseline network.\n",
    "        #       Also, if you do design your own network, include an explanation \n",
    "        #       for your choice of network and how it may be better than the \n",
    "        #       baseline network.\n",
    "        \n",
    "        #Begin Your Code\n",
    "\n",
    "\n",
    "        #End Your Code\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      #TODO : Implement the forward function that applies the layers you have created to the input\n",
    "\n",
    "      #Begin Your Code\n",
    "\n",
    "\n",
    "      #End Your Code\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jieF6xy__X13"
   },
   "source": [
    "## 4. Define a Loss function and optimizer\n",
    "We will be using [Cross Entropy Loss](https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss) and [Adam optimizer](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam).  \n",
    "Note: PyTorch's CrossEntropyLoss combines log softmax and negative log likelihood loss in one class. Make sure you are not computing softmax twice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5-Qn1ef_X13"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#TODO : Use appropriate loss criterion and optimizer \n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "criterion = \n",
    "optimizer = \n",
    "\n",
    "#End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4za3t0b_X15"
   },
   "source": [
    "## 5. Train the network\n",
    "\n",
    "Here we are going to train the network while logging the per batch metrics.  \n",
    "This would take some time to run (5-10 minutes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7y1qZI1wyvv"
   },
   "outputs": [],
   "source": [
    "overall_step = 0\n",
    "\n",
    "#TODO : Select appropriate number of epochs\n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "epochs =\n",
    "\n",
    "#End Your Code\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        #TODO : Make predictions, calculate accuracy and update your weights once\n",
    "\n",
    "        #Begin Your Code\n",
    "\n",
    "        # zero the parameter gradients\n",
    "\n",
    "        # forward + backward + optimize\n",
    "\n",
    "        #End Your Code\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('Epoch: %d, Batch: %5d, loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            #Any thing that is added to the \"info\" gets plotted in tensorboard\n",
    "            #TODO : Add the plots in Tensorboard to the report and explain what is happening\n",
    "            info = { ('loss') : loss.item(),('accuracy'): accuracy.item()}\n",
    "            for tag, value in info.items():\n",
    "                logger.scalar_summary(tag, value, overall_step+1)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RREjngOC_X2F"
   },
   "source": [
    "## 6. Test Accuracy\n",
    "Let us look at how the network performs on the test dataset.  \n",
    "Report your accuracy in your report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTyWZj2R_X2F"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "#TODO : Report this accuracy in your report.\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCCVNEjV_X2G"
   },
   "source": [
    "## 7. Per Class accuracy\n",
    "Now we see the test accuracy for each class in the test dataset.  \n",
    "Report these accuracies in your report. Also identify the problematic classes.  \n",
    "Can you explain why these classes have significantly lower accuracies compared to other classes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CO9h7Zbd_X2H"
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
